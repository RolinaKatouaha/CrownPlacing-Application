# -*- coding: utf-8 -*-
"""New data CrownPlacingVGG16.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ugrgNipko7pZApdFDBiTFCulen0FkSGh
"""

from PIL import Image
import os
import numpy as np
import cv2
from tqdm import tqdm
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelBinarizer
from tensorflow.keras.applications import VGG16
from tensorflow.keras import models, layers
from tensorflow.keras.utils import to_categorical

from google.colab import drive
drive.mount('/content/drive')

!pip install pyheif

######## --------------RGB Data-------------- ########

from PIL import Image
import os
import numpy as np
import pyheif  # For handling HEIC files

# Define your dataset directory
CrownPreparationFile = '/content/drive/MyDrive/one each error final segmentation'

# Define types
types = [
    "Finish line position", "Finish line continuity", "Finish line irregularity", "taper",
    "line angle roundness", "axial wall undercut", "amount of occlusal reduction",
    "Over reduction","Ideal"
]

# Initialize lists to hold images and their labels
CrownPreparationimages = []
CrownPreparationlabels = []

target_size = (128, 128)  # Desired size to resize images

def open_heic_as_jpg(img_path):
    heif_file = pyheif.read(img_path)
    img = Image.frombytes(
        heif_file.mode,
        heif_file.size,
        heif_file.data,
        "raw",
        heif_file.mode,
        heif_file.stride,
    )
    return img


for i, PreparationType in enumerate(types, start=1):
    CrownPreparationFolder = os.path.join(CrownPreparationFile, str(i))
    for file_name in os.listdir(CrownPreparationFolder):
        img_path = os.path.join(CrownPreparationFolder, file_name)
        if os.path.isfile(img_path):
            try:
                if img_path.lower().endswith(".heic"):
                    img = open_heic_as_jpg(img_path)
                else:
                    img = Image.open(img_path)
            except Exception as e:  # Catching all exceptions can simplify error handling
                print(f"Error processing file {img_path}: {e}")
                continue

            img = img.resize(target_size)
            CrownPreparationimages.append(np.array(img))
            CrownPreparationlabels.append(PreparationType)

# Convert lists to numpy arrays
CrownPreparationimages = np.array(CrownPreparationimages)
CrownPreparationlabels = np.array(CrownPreparationlabels)

2################ augmentation part ################

from keras.preprocessing.image import ImageDataGenerator

# Create an instance of the ImageDataGenerator
datagen = ImageDataGenerator(
    rotation_range=5,  # Randomly rotate images by 20 degrees
    horizontal_flip=True,  # Randomly flip images horizontally
    zoom_range=0.05  # Randomly zoom images by 20%
)

# Perform data augmentation
augmented_images = []
augmented_labels = []

for img, label in zip(CrownPreparationimages, CrownPreparationlabels):
    num_augmented_images = 0

    # Reshape the image to (1, height, width, channels)
    img = np.expand_dims(img, axis=0)

    # Generate augmented images
    for batch in datagen.flow(img, batch_size=1):
        augmented_images.append(batch[0])
        augmented_labels.append(label)
        num_augmented_images += 1
        if num_augmented_images >= 15:  # Generate 10 augmented images per original image
        # i change to 15 augmented images per original image
            break

# Convert augmented images and labels to NumPy arrays
CrownPreparationimages = np.array(augmented_images)
CrownPreparationlabels = np.array(augmented_labels)

print("Number of images loaded:", len(CrownPreparationimages))
print("Number of labels:", len(CrownPreparationlabels))

train_images, test_images, train_labels, test_labels = train_test_split(
    CrownPreparationimages, CrownPreparationlabels, test_size=0.2, random_state=42)

# Convert grayscale images to 3-channel grayscale
train_images = np.repeat(train_images[..., np.newaxis], 3, -1)
test_images = np.repeat(test_images[..., np.newaxis], 3, -1)

# Encode labels
label_binarizer = LabelBinarizer()
train_labels_one_hot = label_binarizer.fit_transform(train_labels)
test_labels_one_hot = label_binarizer.transform(test_labels)

def create_vgg16_model(input_shape=(128, 128, 3), num_classes=len(np.unique(CrownPreparationlabels))):
    base_model = VGG16(weights='imagenet', include_top=False, input_shape=input_shape)
    model = models.Sequential([
        base_model,
        layers.Flatten(),
        layers.Dense(256, activation='relu'),
        layers.Dropout(0.5),
        layers.Dense(num_classes, activation='softmax')
    ])
    return model

model = create_vgg16_model()
model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

from keras.callbacks import EarlyStopping

# Define the early stopping criteria
early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)

# Train the model
history = model.fit(train_images, train_labels_one_hot, epochs=100,
                    validation_data=(test_images, test_labels),
                    callbacks=[early_stopping])



import matplotlib.pyplot as plt

plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend(['Train', 'Validation'], loc='upper left')
plt.show()

# Evaluate the model on the test set
test_loss, test_accuracy = model.evaluate(test_images, test_labels_one_hot, verbose=1)

print(f"Test Accuracy: {test_accuracy*100:.2f}%")

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10, 8))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues")
plt.xlabel('Predicted labels')
plt.ylabel('True labels')
plt.title('Confusion Matrix')
plt.show()